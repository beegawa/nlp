{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "friends_nlp_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnWbIxIXpUeZ"
      },
      "source": [
        "## 튜닝용 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C2uoZqzo_zO"
      },
      "source": [
        "gv_epoch = 4 # 3,2,1           변화 미비\n",
        "gv_MAX_LEN = 64 \n",
        "gv_batch_size = 9 #10 ->9  (0.614 10 0.610)\n",
        "gv_model_nm = 'bert-large-cased' #case -uncase 변화\n",
        "gv_do_lower_case = False\n",
        "gv_lr = 4e-6 \n",
        "\n",
        "gv_num_warmup_steps = 0.2\n",
        "gv_eps = 1e-8\n",
        "gv_seed_val = 20200701\n",
        "gv_random_state =  20200701"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAcYmeFAgvCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93061b60-bd58-4690-b469-b3c722a31231"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zByN6QHthMWb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from google.colab import files\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjgawhiIxRdF",
        "outputId": "9bb46583-939f-48ed-b3d4-78c16a8ae629"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsqDjRwOhM8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188780f9-9815-4718-d8ce-0c1e6070fcab"
      },
      "source": [
        "pd_train = pd.read_json(\"/content/gdrive/My Drive/Colab Notebooks/friends_train.json\") \n",
        "pd_test = pd.read_json(\"/content/gdrive/My Drive/Colab Notebooks/friends_test.json\") \n",
        "pd_submit = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/en_data.csv\",encoding=\"UTF-8\") \n",
        "\n",
        "print(pd_train.shape)\n",
        "print(pd_test.shape)\n",
        "print(pd_submit.shape)\n",
        "pd_submit[\"emotion\"] = \"neutral\"\n",
        " "
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(720, 24)\n",
            "(200, 24)\n",
            "(1623, 5)\n",
            "{'speaker': 'Chandler', 'utterance': 'also I was the point person on my company\\x92s transition from the KL-5 to GR-6 system.', 'emotion': 'neutral', 'annotation': '4100000'}\n",
            "{'speaker': 'Mark', 'utterance': 'Why do all you\\x92re coffee mugs have numbers on the bottom?', 'emotion': 'surprise', 'annotation': '2000030'}\n",
            "   id  i_dialog  ...                                          utterance  emotion\n",
            "0   0         0  ...                      Alright, whadyou do with him?  neutral\n",
            "1   1         0  ...                                  Oh! You're awake!  neutral\n",
            "2   2         0  ...  Then you gotta come clean with Ma! This is not...  neutral\n",
            "3   3         0  ...                                  Yeah, but this is  neutral\n",
            "4   4         0  ...          I don't wanna hear it! Now go to my room!  neutral\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "        id  ...  emotion\n",
            "0        0  ...  neutral\n",
            "1        1  ...  neutral\n",
            "2        2  ...  neutral\n",
            "3        3  ...  neutral\n",
            "4        4  ...  neutral\n",
            "...    ...  ...      ...\n",
            "1618  1618  ...  neutral\n",
            "1619  1619  ...  neutral\n",
            "1620  1620  ...  neutral\n",
            "1621  1621  ...  neutral\n",
            "1622  1622  ...  neutral\n",
            "\n",
            "[1623 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2lWoAK0aAWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "39c3ad69-f61e-4df0-ab6f-5aa844c810c6"
      },
      "source": [
        "pd_submit"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>150</td>\n",
              "      <td>14</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Nooo.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>150</td>\n",
              "      <td>15</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>Kate</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>150</td>\n",
              "      <td>17</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>150</td>\n",
              "      <td>18</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, pig!</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...  emotion\n",
              "0        0  ...  neutral\n",
              "1        1  ...  neutral\n",
              "2        2  ...  neutral\n",
              "3        3  ...  neutral\n",
              "4        4  ...  neutral\n",
              "...    ...  ...      ...\n",
              "1618  1618  ...  neutral\n",
              "1619  1619  ...  neutral\n",
              "1620  1620  ...  neutral\n",
              "1621  1621  ...  neutral\n",
              "1622  1622  ...  neutral\n",
              "\n",
              "[1623 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iYgb2QkJsFa"
      },
      "source": [
        "def convert_input_data_flat(p_data):\n",
        "\n",
        "  x = len(p_data.columns)\n",
        "  y = len(p_data[0])\n",
        "\n",
        "  print(\"convert_input_data_flat(x,y) : \" + str(x) + \",\" +str(y) )  \n",
        "\n",
        "  pd_xy = pd.DataFrame()\n",
        "\n",
        "  id = 0 \n",
        "  i_utterance = 0\n",
        "\n",
        "  for j in range(y):\n",
        "    i_utterance = 0\n",
        "    pd_x = pd.DataFrame()\n",
        "    for i in range(x):\n",
        "      #print(i)\n",
        "\n",
        "      if p_data.loc[j,i] != None:\n",
        "        pd_x = pd_x.append(pd.DataFrame.from_dict([p_data.loc[j,i]])  )\n",
        "        id += 1\n",
        "        i_utterance += 1\n",
        "\n",
        "    pd_x.insert(0, \"i_dialog\", j, True)\n",
        "    pd_x.insert(1, \"i_utterance\", range(0,i_utterance), True)\n",
        "    pd_x.drop(['annotation'],axis=1,inplace=True)      \n",
        "    pd_xy = pd_xy.append(pd_x)\n",
        "\n",
        "  pd_xy.insert(0, \"id\", range(0,id), True)    \n",
        "  pd_xy.index = pd_xy[\"id\"]\n",
        "\n",
        "  return pd_xy\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtPNgZl1hNCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14e25a9-e8be-4c1d-b05e-51cf07a31735"
      },
      "source": [
        "train = convert_input_data_flat(pd_train)\n",
        "train[\"utterance\"] = train[\"speaker\"] + \" : \" + train[\"utterance\"]\n",
        "train.drop(['speaker'],axis=1,inplace=True)\n",
        "\n",
        "test = convert_input_data_flat(pd_test)\n",
        "test[\"utterance\"] = test[\"speaker\"] + \" : \" + test[\"utterance\"]\n",
        "test.drop(['speaker'],axis=1,inplace=True)\n",
        "\n",
        "submit = pd.DataFrame(pd_submit)\n",
        "submit[\"utterance\"] = submit[\"speaker\"] + \" : \" + submit[\"utterance\"]\n",
        "submit.drop(['speaker'],axis=1,inplace=True)\n",
        " "
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert_input_data_flat(x,y) : 24,720\n",
            "convert_input_data_flat(x,y) : 24,200\n",
            "(10561, 5)\n",
            "(2764, 5)\n",
            "(1623, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C70PPNmZJItZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "254678ed-0e83-4eef-80ea-38f31eebb137"
      },
      "source": [
        "grouped = train.groupby(train['emotion'])\n",
        "grouped.count()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>non-neutral</th>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  i_dialog  i_utterance  utterance\n",
              "emotion                                            \n",
              "anger         513       513          513        513\n",
              "disgust       240       240          240        240\n",
              "fear          185       185          185        185\n",
              "joy          1283      1283         1283       1283\n",
              "neutral      4752      4752         4752       4752\n",
              "non-neutral  2017      2017         2017       2017\n",
              "sadness       351       351          351        351\n",
              "surprise     1220      1220         1220       1220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJQa3tom_03O"
      },
      "source": [
        "num_labels = {\n",
        "    \"anger\": 0,\n",
        "    \"disgust\": 1,\n",
        "    \"fear\": 2,\n",
        "    \"joy\": 3,\n",
        "    \"neutral\": 4,\n",
        "    \"non-neutral\": 5,\n",
        "    \"sadness\": 6,\n",
        "    \"surprise\": 7\n",
        "}\n",
        "\n",
        "labels_num = {\n",
        "    0 : \"anger\",\n",
        "    1 : \"disgust\",\n",
        "    2 : \"fear\",\n",
        "    3 : \"joy\",\n",
        "    4 : \"neutral\",\n",
        "    5 : \"non-neutral\",\n",
        "    6 : \"sadness\",\n",
        "    7 : \"surprise\"\n",
        "}\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMir3bfiDRA-"
      },
      "source": [
        "train['emotion'] = train['emotion'].replace(num_labels)\n",
        "test['emotion'] = test['emotion'].replace(num_labels)\n",
        "submit['emotion'] = submit['emotion'].replace(num_labels)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TUnLLnUElIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "8560fc5d-4869-4b5c-ff2a-37685f459109"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Chandler : also I was the point person on my c...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>The Interviewer : You mustve had your hands f...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Chandler : That I did. That I did.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>The Interviewer : So lets talk a little bit a...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Chandler : My duties?  All right.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  i_dialog  ...                                          utterance emotion\n",
              "id                ...                                                           \n",
              "0    0         0  ...  Chandler : also I was the point person on my c...       4\n",
              "1    1         0  ...  The Interviewer : You mustve had your hands f...       4\n",
              "2    2         0  ...                 Chandler : That I did. That I did.       4\n",
              "3    3         0  ...  The Interviewer : So lets talk a little bit a...       4\n",
              "4    4         0  ...                  Chandler : My duties?  All right.       7\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dyHiu9D_yD9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "84966ee8-ab1f-4a84-e8c7-a8575c54df13"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Mark : Why do all youre coffee mugs have numb...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Rachel : Oh. Thats so Monica can keep track. ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Rachel : Y'know what?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Ross : It didnt.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Frank : Okay, so what you used to have with Ra...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  i_dialog  ...                                          utterance emotion\n",
              "id                ...                                                           \n",
              "0    0         0  ...  Mark : Why do all youre coffee mugs have numb...       7\n",
              "1    1         0  ...  Rachel : Oh. Thats so Monica can keep track. ...       5\n",
              "2    2         0  ...                              Rachel : Y'know what?       4\n",
              "3    3         0  ...                                  Ross : It didnt.       4\n",
              "4    4         0  ...  Frank : Okay, so what you used to have with Ra...       3\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQQZ9ZihH_sH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f795d56b-4c93-4ffd-fec5-5f6d36bfa370"
      },
      "source": [
        "submit.head()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe : Alright, whadyou do with him?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica : Oh! You're awake!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey : Then you gotta come clean with Ma! This...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani : Yeah, but this is</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey : I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  i_dialog  ...                                          utterance emotion\n",
              "0   0         0  ...             Phoebe : Alright, whadyou do with him?       4\n",
              "1   1         0  ...                         Monica : Oh! You're awake!       4\n",
              "2   2         0  ...  Joey : Then you gotta come clean with Ma! This...       4\n",
              "3   3         0  ...                  Mr. Tribbiani : Yeah, but this is       4\n",
              "4   4         0  ...   Joey : I don't wanna hear it! Now go to my room!       4\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qot1fwWlxs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d4d9a5f9-37e0-4b17-9ea0-217dcf8f248c"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Chandler : also I was the point person on my c...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>The Interviewer : You mustve had your hands f...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Chandler : That I did. That I did.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>The Interviewer : So lets talk a little bit a...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Chandler : My duties?  All right.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  i_dialog  ...                                          utterance emotion\n",
              "id                ...                                                           \n",
              "0    0         0  ...  Chandler : also I was the point person on my c...       4\n",
              "1    1         0  ...  The Interviewer : You mustve had your hands f...       4\n",
              "2    2         0  ...                 Chandler : That I did. That I did.       4\n",
              "3    3         0  ...  The Interviewer : So lets talk a little bit a...       4\n",
              "4    4         0  ...                  Chandler : My duties?  All right.       7\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vgz7V_BgvE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3d57ba-0357-48f5-cfd0-95ecd3559d49"
      },
      "source": [
        "sentences = train['utterance']\n",
        "sentences[:10]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    Chandler : also I was the point person on my c...\n",
              "1    The Interviewer : You mustve had your hands f...\n",
              "2                   Chandler : That I did. That I did.\n",
              "3    The Interviewer : So lets talk a little bit a...\n",
              "4                    Chandler : My duties?  All right.\n",
              "5    The Interviewer : Now youll be heading a whol...\n",
              "6                                    Chandler : I see.\n",
              "7    The Interviewer : But therell be perhaps 30 p...\n",
              "8                             Chandler : Good to know.\n",
              "9              The Interviewer : We can go into detail\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPN35yRuDBLY"
      },
      "source": [
        "sentences_temp = sentences.copy()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  if (i == 0 ): \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  elif (train['i_dialog'][i-1] !=  train['i_dialog'][i]):  \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  else:    \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] \" + str(sentences[i-1]) + \" [SEP]\"\n",
        "\n",
        "sentences = sentences_temp"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Sw1ChcgvHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc301cb7-5611-4c31-8599-1b010182dbc6"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    [CLS] Chandler : also I was the point person o...\n",
              "1    [CLS] The Interviewer : You mustve had your h...\n",
              "2    [CLS] Chandler : That I did. That I did. [SEP]...\n",
              "3    [CLS] The Interviewer : So lets talk a little...\n",
              "4    [CLS] Chandler : My duties?  All right. [SEP] ...\n",
              "5    [CLS] The Interviewer : Now youll be heading ...\n",
              "6    [CLS] Chandler : I see. [SEP] The Interviewer ...\n",
              "7    [CLS] The Interviewer : But therell be perhap...\n",
              "8    [CLS] Chandler : Good to know. [SEP] The Inter...\n",
              "9    [CLS] The Interviewer : We can go into detail ...\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59myVLdyfz2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e9331e-5d7e-414d-cad4-e293076015fd"
      },
      "source": [
        "labels = train[\"emotion\"].values\n",
        "labels"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 7, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtHzODp4fz49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d4b22c-dd49-4b81-d432-58749aba6f46"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(gv_model_nm, do_lower_case=gv_do_lower_case)  \n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Chandler : also I was the point person on my companys transition from the KL-5 to GR-6 system. [SEP] [None] [SEP]\n",
            "['[CLS]', 'Chandler', ':', 'also', 'I', 'was', 'the', 'point', 'person', 'on', 'my', 'company', '##s', 'transition', 'from', 'the', 'K', '##L', '-', '5', 'to', 'G', '##R', '-', '6', 'system', '.', '[SEP]', '[', 'None', ']', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eMUbQWLfz7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7e0d56-f729-49e1-c6e6-f9c7aaf38b4f"
      },
      "source": [
        "MAX_LEN = gv_MAX_LEN\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 14394,   131,  1145,   146,  1108,  1103,  1553,  1825,\n",
              "        1113,  1139,  1419,  1116,  6468,  1121,  1103,   148,  2162,\n",
              "         118,   126,  1106,   144,  2069,   118,   127,  1449,   119,\n",
              "         102,   164,  7330,   166,   102,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676nig_Efz_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b707b570-274c-4dc8-eec8-c51effb39ec7"
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsO8GkWhLNpW"
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=gv_random_state, \n",
        "                                                                                    test_size=0.1)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcvQm0o-LPR3"
      },
      "source": [
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=gv_random_state, \n",
        "                                                       test_size=0.1)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7U9VP66f0CV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb562b4-f57c-4e80-b96d-96be77124750"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels) \n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels) \n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  8958,   131,  1573,  1191,  1103, 21406,  1518,  4390,   117,\n",
            "          146,  1306,  5966,  1214,  1385,  1590,   117,  1150,  1116,  3737,\n",
            "         1104,  1123, 20559,  2069,   119,   102,  8958,   131,   146,  1400,\n",
            "         1122,  1121,  1123,  1165,  1131,  1427,  1106,  2631,   117,  4303,\n",
            "          146,  1180,  1309,  8658,   170,  1282,  1176,  1142,   119,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(4)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([  101, 14394,   131,   146,  1306,  1136,  1256,  2033,  1597,   106,\n",
            "         3956,   117,  1142,  1110,   170,  2304,  1111,  2598,  4211,  5094,\n",
            "          106,   102,  9300,   131,  1327,  1164,  1143,   136,   106,  1192,\n",
            "          118,  1128,  1198,  1163,   146,  1180,   106,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(4)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaWxb0V1f0E3"
      },
      "source": [
        "batch_size = gv_batch_size\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hOveQC4f0Hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a97c17f-173e-4b27-8b9a-c69a3aa426b5"
      },
      "source": [
        "#전처리 - Test Set\n",
        "sentences = test['utterance']\n",
        "sentences[:10]"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    Mark : Why do all youre coffee mugs have numb...\n",
              "1    Rachel : Oh. Thats so Monica can keep track. ...\n",
              "2                                Rachel : Y'know what?\n",
              "3                                    Ross : It didnt.\n",
              "4    Frank : Okay, so what you used to have with Ra...\n",
              "5              Joey : Now, wh-what, what is that like?\n",
              "6    Frank : Its so cool man, its so, its just ...\n",
              "7                                   Ross : Yeah, yeah.\n",
              "8                        Joey : Why cant I find that?\n",
              "9         Ross : Dont ask me, I had it and I blew it!\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubq1rl6eMZ4x"
      },
      "source": [
        "sentences_temp = sentences.copy()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  if (i == 0 ): \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  elif (test['i_dialog'][i-1] !=  test['i_dialog'][i]):  \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  else:    \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] \" + str(sentences[i-1]) + \" [SEP]\"\n",
        "\n",
        "sentences = sentences_temp"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsw89B05f0J7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddde7199-f3a0-401d-dbf9-682e97ad1c7e"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    [CLS] Mark : Why do all youre coffee mugs hav...\n",
              "1    [CLS] Rachel : Oh. Thats so Monica can keep t...\n",
              "2    [CLS] Rachel : Y'know what? [SEP] Rachel : Oh....\n",
              "3    [CLS] Ross : It didnt. [SEP] Rachel : Y'know ...\n",
              "4    [CLS] Frank : Okay, so what you used to have w...\n",
              "5    [CLS] Joey : Now, wh-what, what is that like? ...\n",
              "6    [CLS] Frank : Its so cool man, its so, its ...\n",
              "7    [CLS] Ross : Yeah, yeah. [SEP] Frank : Its so...\n",
              "8    [CLS] Joey : Why cant I find that? [SEP] Ross...\n",
              "9    [CLS] Ross : Dont ask me, I had it and I blew...\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnQMjIcRfz9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68c5465-eb0f-4717-cdd1-e5886d29aa15"
      },
      "source": [
        "labels = test[\"emotion\"].values\n",
        "labels "
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 5, 4, ..., 4, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W46Y2eMMfzvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0909860-2c1f-47d5-e3ad-ff04e03ce4c2"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(gv_model_nm, do_lower_case=gv_do_lower_case)  \n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Mark : Why do all youre coffee mugs have numbers on the bottom? [SEP] [None] [SEP]\n",
            "['[CLS]', 'Mark', ':', 'Why', 'do', 'all', 'your', '##e', 'coffee', 'mug', '##s', 'have', 'numbers', 'on', 'the', 'bottom', '?', '[SEP]', '[', 'None', ']', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0VbOBg_ibUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987a2cd7-ea05-4cb2-d961-58d90b695954"
      },
      "source": [
        "MAX_LEN = gv_MAX_LEN\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  2392,   131,  2009,  1202,  1155,  1240,  1162,  3538,\n",
              "       15761,  1116,  1138,  2849,  1113,  1103,  3248,   136,   102,\n",
              "         164,  7330,   166,   102,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EOFkQRqibaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1485a80-9175-42f7-d07f-8bed9d0d944d"
      },
      "source": [
        "#어텐션 마스크\n",
        "attention_masks = []\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8ZEyAZWibdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a2087a-844b-439f-cdaf-14312eb75dc1"
      },
      "source": [
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  2392,   131,  2009,  1202,  1155,  1240,  1162,  3538, 15761,\n",
            "         1116,  1138,  2849,  1113,  1103,  3248,   136,   102,   164,  7330,\n",
            "          166,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(7)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OeIpKZkibgM"
      },
      "source": [
        "#배치 사이즈\n",
        "batch_size = gv_batch_size\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYWyLMG3k1I6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "7395137c-3582-4c38-f57b-e845a31fb730"
      },
      "source": [
        "## 전처리 - Submit Set\r\n",
        "submit"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe : Alright, whadyou do with him?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica : Oh! You're awake!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey : Then you gotta come clean with Ma! This...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani : Yeah, but this is</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey : I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>150</td>\n",
              "      <td>14</td>\n",
              "      <td>Joey : Nooo.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>150</td>\n",
              "      <td>15</td>\n",
              "      <td>Lauren : Hi, Kate!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>Kate : Hi, Lauren.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>150</td>\n",
              "      <td>17</td>\n",
              "      <td>Joey : Hi, Lauren.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>150</td>\n",
              "      <td>18</td>\n",
              "      <td>Lauren : Hi, pig!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...  emotion\n",
              "0        0  ...        4\n",
              "1        1  ...        4\n",
              "2        2  ...        4\n",
              "3        3  ...        4\n",
              "4        4  ...        4\n",
              "...    ...  ...      ...\n",
              "1618  1618  ...        4\n",
              "1619  1619  ...        4\n",
              "1620  1620  ...        4\n",
              "1621  1621  ...        4\n",
              "1622  1622  ...        4\n",
              "\n",
              "[1623 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ampEXhPJFynx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979430c3-bc39-449c-cba8-7bb06247e3d5"
      },
      "source": [
        "sentences = submit['utterance']\n",
        "sentences[:10]"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               Phoebe : Alright, whadyou do with him?\n",
              "1                           Monica : Oh! You're awake!\n",
              "2    Joey : Then you gotta come clean with Ma! This...\n",
              "3                    Mr. Tribbiani : Yeah, but this is\n",
              "4     Joey : I don't wanna hear it! Now go to my room!\n",
              "5    Chandler : I don?t want him to tell this story...\n",
              "6    Ross : Oh, but he will. He still tells the sto...\n",
              "7                          Monica : I wasn?t escaping.\n",
              "8    Ross : Then how did you get caught in the barb...\n",
              "9        Monica : I was trying to help out a squirrel.\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxCxWo5ZMeb2"
      },
      "source": [
        "sentences_temp = sentences.copy()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  if (i == 0 ): \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  elif (submit['i_dialog'][i-1] !=  submit['i_dialog'][i]):  \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  else:    \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] \" + str(sentences[i-1]) + \" [SEP]\"\n",
        "\n",
        "sentences = sentences_temp"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFZoHukRFzG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55560c34-9ea2-4d90-a875-5cd246c02e07"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [CLS] Phoebe : Alright, whadyou do with him? [...\n",
              "1    [CLS] Monica : Oh! You're awake! [SEP] Phoebe ...\n",
              "2    [CLS] Joey : Then you gotta come clean with Ma...\n",
              "3    [CLS] Mr. Tribbiani : Yeah, but this is [SEP] ...\n",
              "4    [CLS] Joey : I don't wanna hear it! Now go to ...\n",
              "5    [CLS] Chandler : I don?t want him to tell this...\n",
              "6    [CLS] Ross : Oh, but he will. He still tells t...\n",
              "7    [CLS] Monica : I wasn?t escaping. [SEP] Ross :...\n",
              "8    [CLS] Ross : Then how did you get caught in th...\n",
              "9    [CLS] Monica : I was trying to help out a squi...\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v-VanXHF0DP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5388b420-76f5-4bfd-eb7f-dce603dace26"
      },
      "source": [
        "labels = submit[\"emotion\"].values\n",
        "labels "
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Ftr2GTF0Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efd4501-b11d-4e02-9f53-64080fe1d3ae"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(gv_model_nm, do_lower_case=gv_do_lower_case)  \n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Phoebe : Alright, whadyou do with him? [SEP] [None] [SEP]\n",
            "['[CLS]', 'Phoebe', ':', 'Alright', ',', 'w', '##hady', '##ou', 'do', 'with', 'him', '?', '[SEP]', '[', 'None', ']', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8GTUWYlFz7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50455ea7-4c10-4142-cb5f-f0558147b161"
      },
      "source": [
        "MAX_LEN = gv_MAX_LEN\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 19704,   131, 18009,   117,   192, 24905,  6094,  1202,\n",
              "        1114,  1140,   136,   102,   164,  7330,   166,   102,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsdZ_PczFz5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5aa6f5-7eda-489c-923f-f5c9dc54d09f"
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6lUkjSOF8gJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab514d96-171c-429f-9aff-c6afd10675d5"
      },
      "source": [
        "submit_inputs = torch.tensor(input_ids)\n",
        "submit_labels = torch.tensor(labels)\n",
        "submit_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(submit_inputs[0])\n",
        "print(submit_labels[0])\n",
        "print(submit_masks[0])"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101, 19704,   131, 18009,   117,   192, 24905,  6094,  1202,  1114,\n",
            "         1140,   136,   102,   164,  7330,   166,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(4)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1V0fbPjF8eC"
      },
      "source": [
        "batch_size = gv_batch_size\n",
        "submit_data = TensorDataset(submit_inputs, submit_masks, submit_labels)\n",
        "submit_sampler = SequentialSampler(submit_data)\n",
        "submit_dataloader = DataLoader(submit_data, sampler=submit_sampler, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuYr4hP_ibYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46303a3-93ff-4360-e5b3-acfc6c3200a2"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "#\n",
        "i#f device_name == '/device:GPU:0':\n",
        " #   print('Found GPU at: {}'.format(device_name))\n",
        "#else:\n",
        "#    raise SystemError('GPU device not found')\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYO3GFYKijix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91088673-9a35-435c-b3f2-41f92c0a154c"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVjA7N3AijoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce777b2-76e7-4f5a-e426-c8740b33b73f"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(gv_model_nm, num_labels=8)\n",
        "#model.cuda()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqixfflPijri"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = gv_lr, eps = gv_eps )\n",
        "epochs = gv_epoch\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = gv_num_warmup_steps,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju-dBByNijmE"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VinLTPp1vaET"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPUzq7_A706w"
      },
      "source": [
        "seed_val = gv_seed_val\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "model.zero_grad()"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFqLOoU8O-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6fbf1d-46c7-4137-95d9-34c726e61abb"
      },
      "source": [
        "t0 = time.time()\n",
        "total_loss = 0\n",
        "model.train()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inxRy3Vf8n1K"
      },
      "source": [
        "for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    model.to(device) #모델 CUDA 초기화\n",
        "\n",
        "    outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuuZMU4svgNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb55320e-f584-4815-954b-13c6558a4fb5"
      },
      "source": [
        "for epoch_i in range(0, epochs):\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)           \n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():     \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "            \n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  예상 Score : {0:.3f}\".format(eval_accuracy/nb_eval_steps))\n"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  예상 Score : 0.607\n",
            "  예상 Score : 0.616\n",
            "  예상 Score : 0.631\n",
            "  예상 Score : 0.621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxjZ3287IX4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e5ef90-685f-4d32-e80c-57752ae70382"
      },
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "submit_preds =  []\n",
        "\n",
        "for step, batch in enumerate(submit_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "  \n",
        "    if step < 10:\n",
        "      print(step)\n",
        "      print(submit_preds[0:10])\n",
        "      print(logits.argmax(-1))    \n",
        "    submit_preds.extend(logits.argmax(-1))     \n",
        "    if step < 10:\n",
        "      print(submit_preds[0:10])   \n",
        "    \n",
        "print(\"예상 Score : {0:.3f}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예상 Score : 0.556\n",
            "0\n",
            "[]\n",
            "[4 7 5 4 0 6 4 4 4]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4]\n",
            "예상 Score : 0.500\n",
            "1\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4]\n",
            "[4 0 4 4 4 3 7 6 7]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.444\n",
            "2\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[5 4 4 4 7 5 3 0 0]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.417\n",
            "3\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[0 0 0 5 4 6 4 4 5]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.467\n",
            "4\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[4 4 7 4 4 4 7 5 4]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.500\n",
            "5\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[7 5 6 4 4 4 4 4 4]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.476\n",
            "6\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[4 4 7 3 5 5 6 4 5]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.472\n",
            "7\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[4 4 5 4 7 0 3 7 4]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.444\n",
            "8\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[4 3 4 0 5 5 5 0 6]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.444\n",
            "9\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "[7 4 3 4 3 3 4 4 7]\n",
            "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]\n",
            "예상 Score : 0.475\n",
            "예상 Score : 0.472\n",
            "예상 Score : 0.496\n",
            "예상 Score : 0.492\n",
            "예상 Score : 0.489\n",
            "예상 Score : 0.500\n",
            "예상 Score : 0.503\n",
            "예상 Score : 0.519\n",
            "예상 Score : 0.503\n",
            "예상 Score : 0.511\n",
            "예상 Score : 0.524\n",
            "예상 Score : 0.540\n",
            "예상 Score : 0.536\n",
            "예상 Score : 0.537\n",
            "예상 Score : 0.538\n",
            "예상 Score : 0.538\n",
            "예상 Score : 0.531\n",
            "예상 Score : 0.524\n",
            "예상 Score : 0.513\n",
            "예상 Score : 0.511\n",
            "예상 Score : 0.509\n",
            "예상 Score : 0.510\n",
            "예상 Score : 0.515\n",
            "예상 Score : 0.526\n",
            "예상 Score : 0.527\n",
            "예상 Score : 0.528\n",
            "예상 Score : 0.523\n",
            "예상 Score : 0.520\n",
            "예상 Score : 0.510\n",
            "예상 Score : 0.511\n",
            "예상 Score : 0.515\n",
            "예상 Score : 0.524\n",
            "예상 Score : 0.519\n",
            "예상 Score : 0.518\n",
            "예상 Score : 0.511\n",
            "예상 Score : 0.500\n",
            "예상 Score : 0.508\n",
            "예상 Score : 0.512\n",
            "예상 Score : 0.522\n",
            "예상 Score : 0.520\n",
            "예상 Score : 0.523\n",
            "예상 Score : 0.519\n",
            "예상 Score : 0.518\n",
            "예상 Score : 0.512\n",
            "예상 Score : 0.513\n",
            "예상 Score : 0.512\n",
            "예상 Score : 0.515\n",
            "예상 Score : 0.519\n",
            "예상 Score : 0.524\n",
            "예상 Score : 0.526\n",
            "예상 Score : 0.526\n",
            "예상 Score : 0.523\n",
            "예상 Score : 0.517\n",
            "예상 Score : 0.514\n",
            "예상 Score : 0.513\n",
            "예상 Score : 0.512\n",
            "예상 Score : 0.506\n",
            "예상 Score : 0.503\n",
            "예상 Score : 0.502\n",
            "예상 Score : 0.502\n",
            "예상 Score : 0.504\n",
            "예상 Score : 0.505\n",
            "예상 Score : 0.504\n",
            "예상 Score : 0.503\n",
            "예상 Score : 0.499\n",
            "예상 Score : 0.493\n",
            "예상 Score : 0.492\n",
            "예상 Score : 0.496\n",
            "예상 Score : 0.501\n",
            "예상 Score : 0.500\n",
            "예상 Score : 0.497\n",
            "예상 Score : 0.500\n",
            "예상 Score : 0.501\n",
            "예상 Score : 0.500\n",
            "예상 Score : 0.503\n",
            "예상 Score : 0.505\n",
            "예상 Score : 0.501\n",
            "예상 Score : 0.499\n",
            "예상 Score : 0.496\n",
            "예상 Score : 0.494\n",
            "예상 Score : 0.493\n",
            "예상 Score : 0.493\n",
            "예상 Score : 0.491\n",
            "예상 Score : 0.491\n",
            "예상 Score : 0.490\n",
            "예상 Score : 0.492\n",
            "예상 Score : 0.491\n",
            "예상 Score : 0.488\n",
            "예상 Score : 0.489\n",
            "예상 Score : 0.489\n",
            "예상 Score : 0.486\n",
            "예상 Score : 0.484\n",
            "예상 Score : 0.481\n",
            "예상 Score : 0.481\n",
            "예상 Score : 0.480\n",
            "예상 Score : 0.478\n",
            "예상 Score : 0.480\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.479\n",
            "예상 Score : 0.480\n",
            "예상 Score : 0.480\n",
            "예상 Score : 0.483\n",
            "예상 Score : 0.484\n",
            "예상 Score : 0.484\n",
            "예상 Score : 0.485\n",
            "예상 Score : 0.486\n",
            "예상 Score : 0.482\n",
            "예상 Score : 0.481\n",
            "예상 Score : 0.482\n",
            "예상 Score : 0.481\n",
            "예상 Score : 0.482\n",
            "예상 Score : 0.485\n",
            "예상 Score : 0.488\n",
            "예상 Score : 0.488\n",
            "예상 Score : 0.491\n",
            "예상 Score : 0.490\n",
            "예상 Score : 0.490\n",
            "예상 Score : 0.490\n",
            "예상 Score : 0.489\n",
            "예상 Score : 0.487\n",
            "예상 Score : 0.486\n",
            "예상 Score : 0.488\n",
            "예상 Score : 0.486\n",
            "예상 Score : 0.487\n",
            "예상 Score : 0.488\n",
            "예상 Score : 0.488\n",
            "예상 Score : 0.488\n",
            "예상 Score : 0.486\n",
            "예상 Score : 0.483\n",
            "예상 Score : 0.482\n",
            "예상 Score : 0.481\n",
            "예상 Score : 0.482\n",
            "예상 Score : 0.481\n",
            "예상 Score : 0.480\n",
            "예상 Score : 0.481\n",
            "예상 Score : 0.479\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.477\n",
            "예상 Score : 0.475\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.478\n",
            "예상 Score : 0.479\n",
            "예상 Score : 0.478\n",
            "예상 Score : 0.477\n",
            "예상 Score : 0.478\n",
            "예상 Score : 0.478\n",
            "예상 Score : 0.475\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.477\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.477\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.474\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.475\n",
            "예상 Score : 0.476\n",
            "예상 Score : 0.475\n",
            "예상 Score : 0.473\n",
            "예상 Score : 0.473\n",
            "예상 Score : 0.474\n",
            "예상 Score : 0.474\n",
            "예상 Score : 0.473\n",
            "예상 Score : 0.473\n",
            "예상 Score : 0.474\n",
            "예상 Score : 0.473\n",
            "예상 Score : 0.474\n",
            "예상 Score : 0.474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnAl3oDi_gsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9529a17-79b7-4e26-d8c8-6795f9e17c37"
      },
      "source": [
        "submit_preds[0:10]"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 7, 5, 4, 0, 6, 4, 4, 4, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rJaFyiT_7fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e413ba0-7f83-4431-83d0-e672a97a8c3f"
      },
      "source": [
        "logits.argmax(-1)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjytFtb3ayP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093ecaac-5715-47d1-9218-60e99a27dbf7"
      },
      "source": [
        "print([labels_num[submit_pred] for submit_pred in submit_preds])"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neutral', 'surprise', 'non-neutral', 'neutral', 'anger', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'sadness', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'joy', 'anger', 'anger', 'anger', 'anger', 'anger', 'non-neutral', 'neutral', 'sadness', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'non-neutral', 'non-neutral', 'sadness', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'anger', 'joy', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'anger', 'non-neutral', 'non-neutral', 'non-neutral', 'anger', 'sadness', 'surprise', 'neutral', 'joy', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'joy', 'neutral', 'non-neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'surprise', 'joy', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'non-neutral', 'surprise', 'joy', 'neutral', 'anger', 'joy', 'neutral', 'anger', 'joy', 'neutral', 'neutral', 'sadness', 'non-neutral', 'joy', 'joy', 'joy', 'surprise', 'surprise', 'anger', 'neutral', 'surprise', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'anger', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'sadness', 'sadness', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'joy', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'joy', 'joy', 'joy', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'sadness', 'non-neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'joy', 'non-neutral', 'anger', 'joy', 'non-neutral', 'non-neutral', 'anger', 'non-neutral', 'anger', 'anger', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'anger', 'anger', 'anger', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'non-neutral', 'joy', 'joy', 'surprise', 'surprise', 'neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'anger', 'sadness', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'joy', 'neutral', 'anger', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'joy', 'non-neutral', 'joy', 'surprise', 'neutral', 'joy', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'joy', 'anger', 'anger', 'non-neutral', 'non-neutral', 'neutral', 'joy', 'neutral', 'surprise', 'sadness', 'sadness', 'neutral', 'sadness', 'neutral', 'sadness', 'non-neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'surprise', 'neutral', 'joy', 'joy', 'neutral', 'surprise', 'anger', 'neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'surprise', 'surprise', 'surprise', 'joy', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'non-neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'neutral', 'surprise', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'anger', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'surprise', 'anger', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'surprise', 'joy', 'surprise', 'non-neutral', 'sadness', 'anger', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'sadness', 'sadness', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'anger', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'neutral', 'non-neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'surprise', 'surprise', 'surprise', 'non-neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'anger', 'joy', 'joy', 'joy', 'surprise', 'surprise', 'surprise', 'neutral', 'surprise', 'non-neutral', 'anger', 'non-neutral', 'neutral', 'anger', 'anger', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'neutral', 'joy', 'non-neutral', 'joy', 'surprise', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'anger', 'sadness', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'anger', 'surprise', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'surprise', 'surprise', 'joy', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'joy', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'sadness', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'neutral', 'neutral', 'surprise', 'surprise', 'joy', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'surprise', 'joy', 'surprise', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'non-neutral', 'joy', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'anger', 'anger', 'anger', 'neutral', 'neutral', 'anger', 'non-neutral', 'sadness', 'sadness', 'surprise', 'neutral', 'anger', 'surprise', 'non-neutral', 'non-neutral', 'anger', 'neutral', 'non-neutral', 'neutral', 'anger', 'neutral', 'joy', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'surprise', 'joy', 'neutral', 'surprise', 'joy', 'neutral', 'sadness', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'anger', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'surprise', 'joy', 'neutral', 'joy', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'non-neutral', 'surprise', 'joy', 'neutral', 'joy', 'joy', 'neutral', 'sadness', 'non-neutral', 'non-neutral', 'anger', 'surprise', 'anger', 'surprise', 'anger', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'surprise', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'joy', 'surprise', 'surprise', 'surprise', 'neutral', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'surprise', 'non-neutral', 'surprise', 'non-neutral', 'anger', 'non-neutral', 'surprise', 'joy', 'sadness', 'surprise', 'non-neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'sadness', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'sadness', 'non-neutral', 'surprise', 'surprise', 'non-neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'joy', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'anger', 'anger', 'anger', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'sadness', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'joy', 'surprise', 'surprise', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'neutral', 'neutral', 'joy', 'neutral', 'surprise', 'surprise', 'surprise', 'anger', 'surprise', 'non-neutral', 'neutral', 'surprise', 'surprise', 'joy', 'surprise', 'joy', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'sadness', 'neutral', 'non-neutral', 'anger', 'neutral', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'sadness', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'anger', 'anger', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'anger', 'surprise', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'neutral', 'non-neutral', 'surprise', 'joy', 'joy', 'joy', 'joy', 'neutral', 'anger', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'anger', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'sadness', 'neutral', 'sadness', 'non-neutral', 'joy', 'neutral', 'neutral', 'joy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh9Tg6I7zF6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd67c4de-66fc-4933-d5cd-a4ebb691735e"
      },
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"예상 Score : {0:.3f}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예상 Score : 0.630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5RG8gN-o5f4"
      },
      "source": [
        "submit_pred_labels = [labels_num[submit_pred] for submit_pred in submit_preds]"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVdL_WXhbtuV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "77ebf779-e60d-47ca-84a7-b536e8285c1f"
      },
      "source": [
        "submission_dic = {\"id\":list(range(len(submit_pred_labels))), \"Predicted\":submit_pred_labels} \n",
        "submission_df = pd.DataFrame(submission_dic) \n",
        "submission_df.to_csv(\"freinds_nlp_2019511002.csv\", index=False)\n",
        "files.download(\"freinds_nlp_2019511002.csv\")"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b999ba9a-48fe-4e1a-a122-01ce285cc851\", \"freinds_nlp_2019511002.csv\", 20467)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}